\documentclass[a4paper,12pt]{report}

\usepackage{ucs}
\usepackage[utf8x]{inputenc} % Input encoding for Greek characters
\usepackage[greek,english]{babel} % Language support

\newcommand{\en}{\selectlanguage{english}}
\newcommand{\gr}{\selectlanguage{greek}}

% \usepackage{algorithm2e}
% \usepackage{algorithm}
% \usepackage{algorithmic}
\usepackage{enumitem}
\usepackage{float}
\usepackage{amsmath}
\usepackage{graphicx} % For including images
\usepackage{titlesec} % Custom title formatting
\usepackage{fancyhdr} % For custom headers and footers
\usepackage{geometry} % For adjusting page margins

% Adjust the page margins to make content wider
\geometry{top=2.5cm, bottom=2.5cm, left=2.5cm, right=2.5cm}

% Redefine chapter formatting to make it smaller
\titleformat{\chapter}[display]
    {\normalfont\LARGE\bfseries} % Smaller size and bold for chapter heading
    {\chaptername\ \thechapter} % Chapter number format
    {15pt} % Space between chapter number and title
    {\bfseries} % Smaller size and bold for chapter title
\begin{document}

\begin{titlepage}
    \centering
    \vspace*{-3cm}
    % University logo
    \includegraphics[width=1\textwidth]{auth_logo.png} % Replace with your actual logo file

    % University name in Greek
    \textbf{\gr ΑΡΙΣΤΟΤΕΛΕΙΟ ΠΑΝΕΠΙΣΤΗΜΙΟ ΘΕΣΣΑΛΟΝΙΚΗΣ}
    \vspace{2cm}

    % Document title and subtitle in Greek
    \LARGE\textbf{\gr Τεχνικές Βελτιστοποίησης Αναφορά} \\
    \Large\normalfont{\gr Εργασία 2} \\
    \vspace{4cm}

    \gr
    \large
    \textbf{Διακολουκάς Δημήτριος} \\
    \textbf{AEM 10642}
    \vspace{2.5cm}

    \en
    \textit{Email: ddiakolou@ece.auth.gr}
\end{titlepage}

\gr
\tableofcontents

\chapter{\gr Ορισμός και σχεδιασμός συνάρτησης}
Ο στόχος αυτής της ανάλυσης είναι να παρουσιάσει και να σχολιάσει τα αποτελέσματα της ελαχιστοποίησης της συνάρτησης:
\[
f(x, y) = x^5 e^{-x^2-y^2}.
\]
Για την επίλυση του προβλήματος χρησιμοποιήθηκαν τρεις μέθοδοι βελτιστοποίησης: η μέθοδος της μέγιστης καθόδου (\en Steepest Descent\gr), η μέθοδος του Νεύτωνα (\en Newton\gr), και η μέθοδος \en Levenberg-Marquardt\gr. 

\vspace{0.5cm}

\hspace{-0.6cm}Η παρούσα εργασία επικεντρώνεται στην επίλυση προβλημάτων ελαχιστοποίησης συναρτήσεων πολλών μεταβλητών χωρίς περιορισμούς, χρησιμοποιώντας τις παραπάνω τρεις μεθόδους.

\vspace{0.5cm}

\hspace{-0.6cm}Η ανάλυση αποσκοπεί στη σύγκριση της απόδοσής τους ως προς την ταχύτητα σύγκλισης, την ακρίβεια, και τη σταθερότητα, λαμβάνοντας υπόψη διαφορετικές αρχικές συνθήκες και στρατηγικές προσαρμογής βημάτων. 

\vspace{0.5cm}

\hspace{-0.6cm}Η υλοποίηση των αλγορίθμων πραγματοποιήθηκε σε περιβάλλον \en \textit{Matlab}\gr, και τα αποτελέσματα συνοδεύονται από σχολιασμό και εξαγωγή χρήσιμων συμπερασμάτων. Η εργασία απαιτεί τόσο τη θεωρητική κατανόηση των μεθόδων όσο και την πρακτική εφαρμογή τους, παρέχοντας μια ολοκληρωμένη εικόνα των προσεγγίσεων βελτιστοποίησης. Έτσι λοιπόν, όπως φαίνεται και στο Σχήμα 1.1 έχουμε την \(3D\) αναπαράσταση της αντικειμενικής συνάρτησης.

\begin{figure}[ht!]
    \centering
    \includegraphics[width=1\textwidth]{sxima1.png} 
    \caption{Γενική εικόνα της μορφής της \(f\).}
\end{figure}

\vspace{0.5cm}

\hspace{-0.6cm}'Οπως αλλωστε φαίνεται και στο σχήμα, από την ανάλυση του τρισδιάστατου γραφήματος της συνάρτησης \(f\), διαπιστώνεται ότι η ελάχιστη τιμή της εντοπίζεται για αρνητικές τιμές του \(x\), κοντά στο σημείο όπου ο άξονας \(x\) τέμνει τον άξονα \(y\). Από την άλλη πλευρά, ένα μέγιστο εμφανίζεται στις θετικές τιμές του \(x\) στην περιοχή κοντά στο σημείο όπου ο άξονας \(x\) τέμνει τον \(y\).

\hspace{-0.6cm}Ο αντίστοιχος κώδικας βρίσκεται στο αρχείο \en \textbf{Part1.m}\gr.

\chapter{Μέθοδος Μέγιστης Καθόδου \en (Steepest Descent) \gr}

Στο συγκεκριμένο ερώτημα, εξετάζεται η εφαρμογή της μεθόδου Μεγίστης Καθόδου για την ελαχιστοποίηση της συνάρτησης \(f(x, y)\), λαμβάνοντας υπόψη διαφορετικές αρχικές συνθήκες και στρατηγικές επιλογής του βήματος \(\gamma_k\). Στόχος είναι να αναλυθεί πώς οι παράμετροι αυτές επηρεάζουν την απόδοση του αλγορίθμου, τόσο ως προς τη σύγκλιση όσο και ως προς την ακρίβεια του τελικού αποτελέσματος.

\vspace{0.5cm}

\hspace{-0.6cm}Ειδικότερα, η μέθοδος εφαρμόζεται ξεκινώντας από τα αρχικά σημεία \((x_0, y_0) = (0,0)\), \((-1,1)\), και \((1,-1)\), με τρεις διαφορετικές προσεγγίσεις για την επιλογή του \(\gamma_k\): 
\begin{enumerate}
    \item Σταθερή τιμή, που ορίζεται από τον χρήστη (την όρισα 0.1),
    \item Υπολογισμός για την ελαχιστοποίηση της \(f(x_k + \gamma_k d_k)\),
    \item Χρήση του κανόνα \en Armijo\gr.
\end{enumerate}

\hspace{-0.6cm}Η ανάλυση αποσκοπεί στη σύγκριση των αποτελεσμάτων, εντοπίζοντας πιθανές διαφορές λόγω της επιλογής του αρχικού σημείου ή του τρόπου καθορισμού του βήματος. Επιπλέον, εξετάζεται αν ο αλγόριθμος οδηγεί πάντοτε σε σωστά αποτελέσματα και, σε περίπτωση αποκλίσεων, διερευνώνται τα αίτια αυτών.

\subsection*{Ιδιαιτερότητα Σημείου Αρχικοποίησης}

Κατά την αρχικοποίηση του αλγόριθμου στο σημείο \((0, 0)\), παρατηρείται ότι όλοι οι αλγόριθμοι τερματίζουν αμέσως. Αυτό είναι λογικό, καθώς το συγκεκριμένο σημείο ικανοποιεί τη συνθήκη τερματισμού
\[
|\nabla f| < \epsilon, \quad \epsilon > 0.
\]
Η συνάρτηση κλίσης, δεδομένη από τη σχέση:
\[
\nabla f = 
\begin{bmatrix} 
5x^4 e^{-x^2-y^2} - 2x^6 e^{-x^2-y^2} \\ 
-2x^5y e^{-x^2-y^2}
\end{bmatrix},
\]
μηδενίζεται στο \((0, 0)\). Συνεπώς, το σημείο αυτό αναγνωρίζεται ως σημείο εγκλωβισμού, καθιστώντας το μη κατάλληλο για την έναρξη της διαδικασίας βελτιστοποίησης.

\subsection*{Υλοποίηση των Μεθόδων Βελτιστοποίησης}

Στην παρούσα ανάλυση, η μέθοδος Μεγίστης Καθόδου \en (\textit{Steepest Descent}) \gr υλοποιείται με τέσσερις διαφορετικές στρατηγικές επιλογής του βήματος \(\gamma_k\), για την ελαχιστοποίηση της συνάρτησης \(f(x, y)\). Η διαδικασία περιγράφεται γενικά ως εξής:

\subsubsection*{Γενική Διαδικασία}
Η μέθοδος Μεγίστης Καθόδου ξεκινά από ένα αρχικό σημείο \(\mathbf{x}_0 = [x_0, y_0]^\top\) και επαναλαμβάνει τα εξής βήματα:
\begin{enumerate}
    \item Υπολογισμός της κατεύθυνσης καθόδου:
    \[
    \mathbf{d}_k = -\nabla f(\mathbf{x}_k),
    \]
    όπου \(\nabla f(\mathbf{x}_k)\) είναι η κλίση της συνάρτησης \(f\) στο σημείο \(\mathbf{x}_k\).
    \item Υπολογισμός του βήματος \(\gamma_k\) σύμφωνα με μία από τις ακόλουθες στρατηγικές.
    \item Ενημέρωση της θέσης:
    \[
    \mathbf{x}_{k+1} = \mathbf{x}_k + \gamma_k \mathbf{d}_k.
    \]
    \item Έλεγχος σύγκλισης: Η διαδικασία σταματά όταν:
    \[
    \|\nabla f(\mathbf{x}_k)\| < \epsilon,
    \]
    όπου \(\epsilon > 0\) είναι μια μικρή προκαθορισμένη τιμή.
\end{enumerate}

\subsubsection*{1. Σταθερό Βήμα \en (\textit{Fixed Step Size}) \en}
Το βήμα \(\gamma_k\) λαμβάνει μία σταθερή τιμή \(\gamma > 0\) που ορίζεται εκ των προτέρων:
\[
\gamma_k = \gamma.
\]

\subsubsection*{2. Βέλτιστο Βήμα μέσω Ελαχιστοποίησης \en (\textit{Optimal Step Size}) \gr}
Το βέλτιστο \(\gamma_k\) υπολογίζεται ως εξής:
\[
\gamma_k = \arg\min_{\gamma > 0} f(\mathbf{x}_k + \gamma \mathbf{d}_k).
\]
Η παραπάνω ελαχιστοποίηση υλοποιείται αριθμητικά, για παράδειγμα με τη μέθοδο \en \textit{fminbnd} \gr του \(MATLAB\) ή τη μέθοδο Χρυσής Τομής.

\subsubsection*{3. Μέθοδος Χρυσής Τομής \en (\textit{Golden Section Search}) \gr}
Η μέθοδος Χρυσού Τομέα χρησιμοποιείται για την αριθμητική ελαχιστοποίηση της \(f(\mathbf{x}_k + \gamma \mathbf{d}_k)\). Στη μέθοδο αυτή:

\begin{enumerate}[label=\roman*)]
    \item Ορίζεται αρχικό διάστημα \([a, b]\) (όπου το όρισα [0, 10]).
    \item Υπολογίζονται τα σημεία:
    \[
    x_1 = a + (1-\gamma)(b-a), \quad x_2 = a + \gamma(b-a),
    \]
    όπου \(\gamma = \frac{\sqrt{5}-1}{2}\).
    \item Επαναλαμβάνεται η διαδικασία σύγκρισης \(f(x_1)\) και \(f(x_2)\), έως ότου το διάστημα \([a, b]\) να ικανοποιεί:
    \[
    b - a < \ell,
    \]
    όπου \(\ell\) είναι μια μικρή προκαθορισμένη ανοχή που ορίστηκε στο 0.0001.
\end{enumerate}

\subsubsection*{4. Κανόνας \en Armijo \gr}
Το \(\gamma_k\) επιλέγεται έτσι ώστε να ικανοποιείται η συνθήκη \en Armijo\gr:
\[
f(\mathbf{x}_k) - f(\mathbf{x}_k + \gamma_k \mathbf{d}_k) \geq -\alpha \gamma_k \nabla f(\mathbf{x}_k)^\top \mathbf{d}_k,
\]
όπου \(0 < \alpha < 1\) είναι σταθερά. Η τιμή \(\gamma_k\) προσαρμόζεται δυναμικά μειώνοντας την αρχική τιμή \(\gamma\) έως ότου η παραπάνω ανισότητα να ισχύει.

\subsubsection*{Σύγκλιση}
Η διαδικασία επαναλαμβάνεται έως ότου το μέγεθος της κλίσης γίνει μικρότερο από ένα προκαθορισμένο όριο:
\[
\|\nabla f(\mathbf{x}_k)\| < \epsilon.
\]

\hspace{-0.6cm}Επιπλέον, για λόγους πρακτικούς θεώρησα ότι αν υπερβαίνει το όριο επαναλήψεων των 40000 να διακόπτει τον αλγόριθμο γιατί δεν έχουμε σύγκλιση.

\vspace{0.5cm}

\hspace{-0.6cm}Στην συνέχεια δημιούργησα και τη γραφική παράσταση της σύγκλισης της αντικειμενικής συνάρτησης ως προς τον αριθμό των επαναλήψεων που απαιτούνται μέχρι να τερματίσει ο αλγόριθμος αλλά και την αναπαράσταση τυχών συγκλίσεων στην αναπαράσταση της συνάρτησης \(f\). Έτσι παρατηρήθηκαν τα παρακάτω αποτελέσματα όπως φαίνονται στα Σχήματα 2.1, 2.2 και 2.3 για αρχικά σημεία \((x_0, y_0) = (0,0)\), \((-1,1)\), και \((1,-1)\) αντίστοιχα.

\begin{figure}[ht!]
    \centering
    \includegraphics[width=1\textwidth]{SD_0_0.png} 
    \caption{Aποτελέσματα για (0, 0) \(f\).}
\end{figure}

\begin{figure}[ht!]
    \centering
    \includegraphics[width=1\textwidth]{SD_meion1_1.png} 
    \caption{Αποτελέσματα για (-1, 1) \(f\).}
\end{figure}

\begin{figure}[ht!]
    \centering
    \includegraphics[width=1\textwidth]{SD_1_meion1.png} 
    \caption{Αποτελέσματα για (1, -1) \(f\).}
\end{figure}

\begin{table}[H]
\centering
\renewcommand{\arraystretch}{2} % Increases row height
\setlength{\tabcolsep}{12pt} % Increases column spacing
\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|}
\hline
& \textbf{\en Fixed Step\gr} & \textbf{\en Optimal Step\gr} & \textbf{\en Armijo \gr} \\ \hline
\en
\textbf{(0, 0)} &Χ   &Χ   &Χ  \\ \hline
\textbf{(-1, 1)} &-0.811174   &-0.811174   &-0.811174  \\ \hline
\textbf{(1, -1)} &Χ   &-0.811174   &-0.811174  \\ \hline
\end{tabular}
\caption{Πίνακας για την καταγραφή της σύγκλισης.}
\label{tab:large_convergence}
\end{table}

\begin{table}[H]
\centering
\renewcommand{\arraystretch}{2} % Increases row height
\setlength{\tabcolsep}{12pt} % Increases column spacing
\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|}
\hline
& \textbf{\en Fixed Step\gr} & \textbf{\en Optimal Step\gr} & \textbf{\en Armijo \gr} \\ \hline
\en
\textbf{(0, 0)} &0   &0   &0  \\ \hline
\textbf{(-1, 1)} &89   &13   &9  \\ \hline
\textbf{(1, -1)} &40000   &12   &16  \\ \hline
\end{tabular}
\caption{Πίνακας για την καταγραφή των επαναλήψεων.}
\label{tab:large_iterations}
\end{table}

\hspace{-0.6cm}Aπό τα σχήματα πολύ εύκολα παρατηρούμε ότι η μέθοδος που υπολογίζει το βήμα με τρόπο που ελαχιστοποιεί τη συνάρτηση απαιτεί λιγότερες επαναλήψεις για να συγκλίνει και έχει ίδια αποτελέσματα είτε υλοποιηθεί με \en fminbnd \gr είτε με μέθοδο του χρυσού τομέα, σε σύγκριση με τη μέθοδο που χρησιμοποιεί σταθερό βήμα. Επιπλέον, η μέθοδος που καθορίζει το βήμα σύμφωνα με τον κανόνα του \en Armijo \gr παρουσιάζει ακόμα καλύτερη απόδοση, καθώς συγκλίνει με ακόμη λιγότερες επαναλήψεις στην περίπτωση (-1, 1), ενώ στο (1, -1) απαιτούνται λιγότερες επαναλήψεις στην μέθοδο εύρεσης βέλτιστου γ άρα έχει καλύτερη απόδοση. Στις περιπτώσεις που στον Πίνακα 2.1 έχουμε ένδειξη \(X\) παρατηρείται εκλωβισμός σε τοπικό ελάχιστο και δεν προσεγγίζεται σωστά το ελάχιστο ή μέγιστο αντίστοιχα.

\hspace{-0.6cm}Ο αντίστοιχος κώδικας βρίσκεται στο αρχείο \en \textbf{Part2.m}\gr.

\chapter{\grΜέθοδος \en Newton \gr}
Ακολουθώντας ακριβώς την ίδια διαδικασία με την μέθοδο \en Steepest Descent \gr θα κληθούμε να υλοποιήσουμε και την μέθοδο \en Newton \gr.

\vspace{0.5cm}

\hspace{-0.6cm}Στο συγκεκριμένο ερώτημα, εξετάζεται η εφαρμογή της μεθόδου Νεύτωνα για την ελαχιστοποίηση της συνάρτησης \(f(x, y)\), λαμβάνοντας υπόψη διαφορετικές αρχικές συνθήκες και στρατηγικές επιλογής του βήματος \(\gamma_k\). Η μέθοδος Νεύτωνα λαμβάνει υπόψη τόσο την κλίση όσο και τη δεύτερη παράγωγο \en (Hessian) \gr της συνάρτησης, για να επιτύχει γρηγορότερη σύγκλιση. Στόχος είναι να αναλυθεί πώς οι παράμετροι αυτές επηρεάζουν την απόδοση του αλγορίθμου, τόσο ως προς τη σύγκλιση όσο και ως προς την ακρίβεια του τελικού αποτελέσματος.

\subsection*{Υλοποίηση της Μεθόδου Νεύτωνα}

Η μέθοδος Νεύτωνα υλοποιείται με τέσσερις διαφορετικές στρατηγικές επιλογής του βήματος \(\gamma_k\), για την ελαχιστοποίηση της συνάρτησης \(f(x, y)\). Η γενική διαδικασία περιγράφεται ως εξής:

\subsubsection*{Γενική Διαδικασία}
Η μέθοδος Νεύτωνα ξεκινά από ένα αρχικό σημείο \(\mathbf{x}_0 = [x_0, y_0]^\top\) και επαναλαμβάνει τα εξής βήματα:
\begin{enumerate}
    \item Υπολογισμός της κατεύθυνσης καθόδου χρησιμοποιώντας την αντίστροφη του πίνακα \en Hessian \gr:
    \[
    \mathbf{d}_k = -[\nabla^2 f(\mathbf{x}_k)]^{-1} \nabla f(\mathbf{x}_k),
    \]
    όπου \(\nabla f(\mathbf{x}_k)\) είναι η κλίση και \(\nabla^2 f(\mathbf{x}_k)\) ο πίνακας \en Hessian \gr της συνάρτησης \(f\) στο σημείο \(\mathbf{x}_k\).
    \item Υπολογισμός του βήματος \(\gamma_k\) σύμφωνα με μία από τις ακόλουθες στρατηγικές.
    \item Ενημέρωση της θέσης:
    \[
    \mathbf{x}_{k+1} = \mathbf{x}_k + \gamma_k \mathbf{d}_k.
    \]
    \item Έλεγχος σύγκλισης: Η διαδικασία σταματά όταν:
    \[
    \|\nabla f(\mathbf{x}_k)\| < \epsilon,
    \]
    όπου \(\epsilon > 0\) είναι μια μικρή προκαθορισμένη τιμή.
\end{enumerate}

\subsubsection*{1. Σταθερό Βήμα \en (\textit{Fixed Step Size}) \gr}
Το βήμα \(\gamma_k\) λαμβάνει μία σταθερή τιμή \(\gamma > 0\) που ορίζεται εκ των προτέρων:
\[
\gamma_k = \gamma.
\]

\subsubsection*{2. Κανόνας \en Armijo \gr}
Το \(\gamma_k\) επιλέγεται έτσι ώστε να ικανοποιείται η συνθήκη \en Armijo\gr:
\[
f(\mathbf{x}_k) - f(\mathbf{x}_k + \gamma_k \mathbf{d}_k) \geq -\alpha \gamma_k \nabla f(\mathbf{x}_k)^\top \mathbf{d}_k,
\]
όπου \(0 < \alpha < 1\) είναι σταθερά. Η τιμή \(\gamma_k\) προσαρμόζεται δυναμικά μειώνοντας την αρχική τιμή \(\gamma\) έως ότου η παραπάνω ανισότητα να ισχύει.

\subsubsection*{3. Βέλτιστο Βήμα μέσω Ελαχιστοποίησης \en (\textit{Optimal Step Size}) \gr}
Το βέλτιστο \(\gamma_k\) υπολογίζεται ως εξής:
\[
\gamma_k = \arg\min_{\gamma > 0} f(\mathbf{x}_k + \gamma \mathbf{d}_k).
\]
Η παραπάνω ελαχιστοποίηση υλοποιείται αριθμητικά, για παράδειγμα με τη μέθοδο \en \textit{fminbnd} \gr του \(MATLAB\).

\subsubsection*{4. Μέθοδος Χρυσής Τομής \en (\textit{Golden Section Search}) \gr}
Η μέθοδος Χρυσής Τομής χρησιμοποιείται για την αριθμητική ελαχιστοποίηση της \(f(\mathbf{x}_k + \gamma \mathbf{d}_k)\) όπως ακριβώς φαίνεται παραπάνω στην μέθοδο μεγίστης καθόδου.

\subsubsection*{Σύγκλιση}
Η διαδικασία επαναλαμβάνεται έως ότου το μέγεθος της κλίσης γίνει μικρότερο από ένα προκαθορισμένο όριο:
\[
\|\nabla f(\mathbf{x}_k)\| < \epsilon.
\]

\hspace{-0.6cm}Επιπλέον, για λόγους πρακτικούς, θεωρήθηκε ότι αν υπερβεί το όριο επαναλήψεων των 40000, ο αλγόριθμος διακόπτει, καθώς θεωρείται ότι δεν υπάρχει σύγκλιση όπως και στην μέθοδο μεγίστης καθόδου.

\vspace{0.5cm}

\hspace{-0.6cm}Στην συνέχεια όπως και πριν αναπαριστώ και τη γραφική παράσταση της σύγκλισης της αντικειμενικής συνάρτησης ως προς τον αριθμό των επαναλήψεων που απαιτούνται μέχρι να τερματίσει ο αλγόριθμος αλλά και την αναπαράσταση τυχών συγκλίσεων στην αναπαράσταση της συνάρτησης \(f\). Έτσι παρατηρήθηκαν τα παρακάτω αποτελέσματα όπως φαίνονται στα Σχήματα 3.1, 3.2 και 3.3 για αρχικά σημεία \((x_0, y_0) = (0,0)\), \((-1,1)\), και \((1,-1)\) αντίστοιχα.

\begin{figure}[ht!]
    \centering
    \includegraphics[width=1\textwidth]{Newton_0_0.png} 
    \caption{Αποτελέσματα για (0, 0) \(f\).}
\end{figure}

\begin{figure}[ht!]
    \centering
    \includegraphics[width=1\textwidth]{Newton_meion1_1.png} 
    \caption{Αποτελέσματα για (-1, 1) \(f\).}
\end{figure}

\begin{figure}[ht!]
    \centering
    \includegraphics[width=1\textwidth]{Newton_1_meion1.png} 
    \caption{Αποτελέσματα για (1, -1) \(f\).}
\end{figure}

\clearpage

\begin{table}[H]
\centering
\renewcommand{\arraystretch}{2} % Increases row height
\setlength{\tabcolsep}{12pt} % Increases column spacing
\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|}
\hline
& \textbf{\en Fixed Step\gr} & \textbf{\en Optimal Step\gr} & \textbf{\en Armijo \gr} \\ \hline
\en
\textbf{(0, 0)} &Χ   &Χ   &Χ  \\ \hline
\textbf{(-1, 1)} &\en X   &\en X   &\en X  \\ \hline
\textbf{(1, -1)} &Χ   &\en X   &\en X  \\ \hline
\end{tabular}
\caption{Πίνακας για την καταγραφή της σύγκλισης.}
\label{tab:large2_convergence}
\end{table}

\begin{table}[H]
\centering
\renewcommand{\arraystretch}{2} % Increases row height
\setlength{\tabcolsep}{12pt} % Increases column spacing
\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|}
\hline
& \textbf{\en Fixed Step\gr} & \textbf{\en Optimal Step\gr} & \textbf{\en Armijo \gr} \\ \hline
\en
\textbf{(0, 0)} &0   &0   &0  \\ \hline
\textbf{(-1, 1)} &131   &40000   &40000  \\ \hline
\textbf{(1, -1)} &131   &13   &2  \\ \hline
\end{tabular}
\caption{Πίνακας για την καταγραφή των επαναλήψεων.}
\label{tab:large2_iterations}
\end{table}

\hspace{-0.6cm}Η μέθοδος του Νεύτωνα, όπως ορίζεται, δεν μπορεί να εφαρμοστεί για τη συγκεκριμένη συνάρτηση. Αυτό συμβαίνει διότι, για να έχει η μέθοδος την ιδιότητα της επαναληπτικής καθόδου και να συγκλίνει σωστά, ο Εσσιανός πίνακας της συνάρτησης \( f \), δηλαδή το \( \nabla^2 f \), πρέπει να είναι θετικά ορισμένος. 

\vspace{0.5cm}

\hspace{-0.6cm}Ωστόσο, για καθένα από τα τρία αρχικά σημεία \((0, 0)\), \((-1, 1)\) και \((1, -1)\), ο πίνακας δεν είναι θετικά ορισμένος. Στην πρώτη περίπτωση έχουμε τον μηδενικό πίνακα, ενώ στις άλλες δύο περιπτώσεις οι ιδιοτιμές του πίνακα είναι οι \( [4e^{-2}, -8e^{-2}] \) και \( [-4e^{-2}, 8e^{-2}] \), οπότε προφανώς ο πίνακας δεν είναι θετικά ορισμένος και η μέθοδος ξεκινάει λανθασμένα από τα πρώτα κιόλας σημεία. 'Ετσι δεν έχουμε καλά συμπεράσματα με την μέθοδο Newton.

\vspace{0.5cm}

\hspace{-0.6cm}Ο αντίστοιχος κώδικας βρίσκεται στο αρχείο \en \textbf{Part3.m}\gr.


\chapter{\gr Μέθοδος \en  Levenberg-Marquardt \gr}
Σε αυτό το ερώτημα για μία ακόμα φορά εξετάζεται η εφαρμογή της μεθόδου \en Levenberg-Marquardt \gr για την ελαχιστοποίηση της συνάρτησης \(f(x, y)\), λαμβάνοντας υπόψη διαφορετικές αρχικές συνθήκες και στρατηγικές επιλογής του βήματος \(\gamma_k\). Η μέθοδος \en Levenberg-Marquardt \gr αποτελεί συνδυασμό της μεθόδου Νεύτωνα και της μεθόδου Μεγίστης Καθόδου, προσφέροντας αυξημένη σταθερότητα μέσω της εισαγωγής μιας παραμέτρου ρύθμισης \(\mu\), η οποία διασφαλίζει ότι ο πίνακας \en Hessian \gr παραμένει θετικά ορισμένος. Στόχος είναι να αναλυθεί πώς οι παράμετροι αυτές επηρεάζουν την απόδοση του αλγορίθμου.

\subsection*{Υλοποίηση της Μεθόδου \en Levenberg-Marquardt \gr}

Η μέθοδος \en Levenberg-Marquardt \gr υλοποιείται με τέσσερις διαφορετικές στρατηγικές επιλογής του βήματος \(\gamma_k\), για την ελαχιστοποίηση της συνάρτησης \(f(x, y)\). Η γενική διαδικασία περιγράφεται ως εξής:

\subsubsection*{Γενική Διαδικασία}
Η μέθοδος \en Levenberg-Marquardt \gr ξεκινά από ένα αρχικό σημείο \(\mathbf{x}_0 = [x_0, y_0]^\top\) και επαναλαμβάνει τα εξής βήματα:
\begin{enumerate}
    \item Υπολογισμός της κατεύθυνσης καθόδου με ρύθμιση μέσω της παραμέτρου \(\mu\):
    \[
    \mathbf{d}_k = -[\nabla^2 f(\mathbf{x}_k) + \mu I]^{-1} \nabla f(\mathbf{x}_k),
    \]
    όπου \(\nabla f(\mathbf{x}_k)\) είναι η κλίση και \(\nabla^2 f(\mathbf{x}_k)\) ο πίνακας \en Hessian \gr της συνάρτησης \(f\) στο σημείο \(\mathbf{x}_k\), ενώ \(I\) είναι ο μοναδιαίος πίνακας.
    \item Υπολογισμός του βήματος \(\gamma_k\) σύμφωνα με μία από τις ακόλουθες στρατηγικές.
    \item Ενημέρωση της θέσης:
    \[
    \mathbf{x}_{k+1} = \mathbf{x}_k + \gamma_k \mathbf{d}_k.
    \]
    \item Έλεγχος σύγκλισης: Η διαδικασία σταματά όταν:
    \[
    \|\nabla f(\mathbf{x}_k)\| < \epsilon,
    \]
    όπου \(\epsilon > 0\) είναι μια μικρή προκαθορισμένη τιμή.
\end{enumerate}

\subsubsection*{1. Σταθερό Βήμα \en (\textit{Fixed Step Size}) \gr}
Το βήμα \(\gamma_k\) λαμβάνει μία σταθερή τιμή \(\gamma > 0\) που ορίζεται εκ των προτέρων:
\[
\gamma_k = \gamma.
\]

\subsubsection*{2. Κανόνας \en Armijo \gr}
Το \(\gamma_k\) επιλέγεται έτσι ώστε να ικανοποιείται η συνθήκη \en Armijo\gr:
\[
f(\mathbf{x}_k) - f(\mathbf{x}_k + \gamma_k \mathbf{d}_k) \geq -\alpha \gamma_k \nabla f(\mathbf{x}_k)^\top \mathbf{d}_k,
\]
όπου \(0 < \alpha < 1\) είναι σταθερά. Η τιμή \(\gamma_k\) προσαρμόζεται δυναμικά μειώνοντας την αρχική τιμή \(\gamma\) έως ότου η παραπάνω ανισότητα να ισχύει.

\subsubsection*{3. Βέλτιστο Βήμα μέσω Ελαχιστοποίησης \en (\textit{Optimal Step Size}) \gr}
Το βέλτιστο \(\gamma_k\) υπολογίζεται ως εξής:
\[
\gamma_k = \arg\min_{\gamma > 0} f(\mathbf{x}_k + \gamma \mathbf{d}_k).
\]
Η παραπάνω ελαχιστοποίηση υλοποιείται αριθμητικά, για παράδειγμα με τη μέθοδο \en \textit{fminbnd} \gr του \(MATLAB\).

\subsubsection*{4. Μέθοδος Χρυσής Τομής \en (\textit{Golden Section Search}) \gr}
Η μέθοδος Χρυσής Τομής χρησιμοποιείται και υλοποιείται όπως δείχτηκε στο Κεφάλαιο 2.

\subsubsection*{Σύγκλιση}
Η διαδικασία επαναλαμβάνεται έως ότου το μέγεθος της κλίσης γίνει μικρότερο από ένα προκαθορισμένο όριο:
\[
\|\nabla f(\mathbf{x}_k)\| < \epsilon.
\]

\hspace{-0.6cm}Ξανά, ο αλγόριθμος διακόπτει στις 40000 επαναλήψεις.

\vspace{0.5cm}

\hspace{-0.6cm}Όπως και στα προηγούμενα 2 ερωτήματα θα δείξω την γραφική παράσταση της σύγκλισης της συνάρτησης ως προς τον αριθμό των επαναλήψεων που απαιτούνται μέχρι να τερματίσει ο αλγόριθμος αλλά και την αναπαράσταση τυχών συγκλίσεων στην αναπαράσταση της συνάρτησης \(f\). Έτσι παρατηρήθηκαν τα παρακάτω αποτελέσματα όπως φαίνονται στα Σχήματα 4.1, 4.2 και 4.3 για αρχικά σημεία \((x_0, y_0) = (0,0)\), \((-1,1)\), και \((1,-1)\) αντίστοιχα.

\begin{figure}[ht!]
    \centering
    \includegraphics[width=1\textwidth]{L_0_0.png} 
    \caption{Αποτελέσματα για (0, 0) \(f\).}
\end{figure}

\begin{figure}[ht!]
    \centering
    \includegraphics[width=1\textwidth]{L_meion1_1.png} 
    \caption{Αποτελέσματα για (-1, 1) \(f\).}
\end{figure}

\begin{figure}[ht!]
    \centering
    \includegraphics[width=1\textwidth]{L_1_meion1.png} 
    \caption{Αποτελέσματα για (1, -1) \(f\).}
\end{figure}

\clearpage

\begin{table}[H]
\centering
\renewcommand{\arraystretch}{2} % Increases row height
\setlength{\tabcolsep}{12pt} % Increases column spacing
\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|}
\hline
& \textbf{\en Fixed Step\gr} & \textbf{\en Optimal Step\gr} & \textbf{\en Armijo \gr} \\ \hline
\en
\textbf{(0, 0)} &Χ   &Χ   &Χ  \\ \hline
\textbf{(-1, 1)} &\en -811174   &\en -0.811174   &\en -0.811174  \\ \hline
\textbf{(1, -1)} &Χ   &\en-0.811174   &\en X  \\ \hline
\end{tabular}
\caption{Πίνακας για την καταγραφή της σύγκλισης.}
\label{tab:large3_convergence}
\end{table}

\begin{table}[H]
\centering
\renewcommand{\arraystretch}{2} % Increases row height
\setlength{\tabcolsep}{12pt} % Increases column spacing
\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|}
\hline
& \textbf{\en Fixed Step\gr} & \textbf{\en Optimal Step\gr} & \textbf{\en Armijo \gr} \\ \hline
\en
\textbf{(0, 0)} &0   &0   &0  \\ \hline
\textbf{(-1, 1)} &138   &4   &13  \\ \hline
\textbf{(1, -1)} &40000   &6 (7 \en Golden Section \gr)   &2188 \\ \hline
\end{tabular}
\caption{Πίνακας για την καταγραφή των επαναλήψεων.}
\label{tab:large3_iterations}
\end{table}

\hspace{-0.6cm}Aπό τα αποτελέσματα παρατηρούμε ότι η μέθοδος \en Levenberg-Marquardt \gr παρουσιάζει αρκετά βελτιωμένη συμπεριφορά σε σύγκριση με την μέθοδο \en Newton \gr, ειδικά όταν συνδυάζεται με δυναμικές στρατηγικές επιλογής βήματος, όπως η εύρεση βέλτιστου \(\gamma\) (είτε με τη μέθοδο \en fminbnd \gr είτε με τη μέθοδο Χρυσής Τομής).

\vspace{0.5cm}

\hspace{-0.6cm}Συγκεκριμένα:
\begin{itemize}
    \item Στην περίπτωση \((-1, 1)\), η μέθοδος \en Levenberg-Marquardt \gr με την εύρεση βέλτιστου \(\gamma\) συγκλίνει σε μόλις λίγες επαναλήψεις (\(6\) ή \(7\), αναλόγως της στρατηγικής), ενώ η μέθοδος με σταθερό βήμα χρειάζεται πολύ περισσότερες επαναλήψεις (\(138\)). Ο κανόνας \en Armijo \gr επίσης επιτυγχάνει αποδοτική σύγκλιση με \(13\) επαναλήψεις.
    \item Στην περίπτωση \((1, -1)\), οι μέθοδοι εύρεσης βέλτιστου \(\gamma\) (π.χ. Χρυσή Τομή) είναι και πάλι εξαιρετικά αποτελεσματικές (\(6\) επαναλήψεις). Ωστόσο, η μέθοδος με σταθερό βήμα αποτυγχάνει να συγκλίνει εντός του ορίου επαναλήψεων (\(40000\) επαναλήψεις), γεγονός που υποδεικνύει ότι η συγκεκριμένη επιλογή βήματος δεν είναι κατάλληλη για αυτή την περίπτωση.
\end{itemize}

\hspace{-0.6cm}Επιπλέον, στις περιπτώσεις που εμφανίζεται ένδειξη \(X\) στον πίνακα, η μέθοδος \en Levenberg-Marquardt \gr ενδέχεται να αντιμετωπίζει δυσκολίες λόγω μη θετικά ορισμένου πίνακα: \[\nabla^2 f(\mathbf{x}_k) + \mu I\]

\hspace{-0.6cm}Έτσι οδηγούμαστε σε \en"\grεγκλωβισμό\en" \gr σε τοπικά ακρώτατα (τοπικό ελάχιστο ή μέγιστο) ή αποτυχία προσέγγισης του ελάχιστου. Αυτό ενισχύει τη σημασία της δυναμικής ρύθμισης της παραμέτρου \(\mu\), ώστε να εξασφαλιστεί η σταθερότητα της μεθόδου. Η αποδοτικότερη επιλογή στην περίπτωση της εφαρμογής μεθόδου \en Levenberg-Marquardt \gr φαίνεται από το Πίνακα 4.2 να είναι η εύρεση βέλτιστου \(\gamma\) ανεξαρτήτως μεθόδου ελαχιστοποίησης που επιλέξαμε.

\hspace{-0.6cm}Ο αντίστοιχος κώδικας βρίσκεται στο αρχείο \en \textbf{Part4.m}\gr.

\chapter{\gr Αποτελέσματα και Συμπεράσματα}
Κατά την εφαρμογή των μεθόδων, παρατηρούμε ότι για αρχικά σημεία όπως το \((1, -1)\) αλλά και το \((-1, 1)\) , η σύγκλιση μπορεί να παρεμποδιστεί από τοπικά ακρότατα, οδηγώντας σε \en"\grπαγίδευση\en" \gr του αλγορίθμου. Για αρχικό σημείο (0, 0) οι μέθοδοι μένουν στάσιμοι χωρίς επανάληψη. Επιπλέον, στρατηγικές όπως η ελαχιστοποίηση του βήματος ή ο κανόνας του \en Armijo \gr μειώνουν σημαντικά τις απαιτούμενες επαναλήψεις για τη σύγκλιση του αλγορίθμου. 
Επιπρόσθετα, η μέθοδος \en Newton \gr, δεν είναι βοηθητική για την συγκεκριμένη διερεύνηση καθώς δεν οδηγεί σε σωστά συμπεράσματα λόγω του μη θετικά ορισμένου πίνακα \( \nabla^2 f(\mathbf{x}_k) \) σε μερικές περιπτώσεις. Τέλος, σχετικά με την επιλογή του \(\gamma_k\), η αποδοτικότερη επιλογή φαίνεται σε πολλές περιπτώσεις να είναι αυτή που οδηγεί στην ελαχιστοποίηση της \(f(\mathbf{x}_k + \gamma_k \mathbf{d}_k).\)

\bibliographystyle{plain}
\begin{thebibliography}{1}
    \bibitem{rovithakis}
    Γεώργιος Α. Ροβιθάκης, \textit{Τεχνικές Βελτιστοποίησης}. Εκδόσεις ΤΖΙΟΛΑ.
\end{thebibliography}

\end{document}
